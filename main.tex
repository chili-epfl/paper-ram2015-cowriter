%\documentclass[twocolumn]{article}
\documentclass{article}

\usepackage[utf8]{inputenc}

\usepackage{graphicx} 
\usepackage{subfigure}
\usepackage{paralist}
\usepackage{amsfonts}
\usepackage{hyperref}

\usepackage{url}
\usepackage{booktabs}

\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tikz}
\usetikzlibrary{positioning, calc}

\usepackage[draft,nomargin,footnote]{fixme}

\graphicspath{{figs/}}

\usepackage{xspace}
\newcommand{\eg}{\textit{e.g.}\xspace}
\newcommand{\etal}{\textit{et al.}\xspace}
\newcommand{\ie}{\textit{i.e.}\xspace}
\newcommand{\etc}{\textit{etc.}\xspace}
\newcommand{\vs}{\textit{vs.}\xspace}
\newcommand{\resp}{\textit{resp.}\xspace}

\title{Learning by Teaching a Robot:\\The Case of Handwriting}

\author{Séverin Lemaignan$^1$, Alexis Jacq$^{1,3}$, Deanna Hood$^1$, Fernando Garcia$^1$, \\
    Aude Billard$^2$, Ana Paiva$^3$, Pierre Dillenbourg$^1$ \\
$^1$CHILI Lab, École Polytechnique Fédérale de Lausanne, Suisse,\\
$^2$LASA, École Polytechnique Fédérale de Lausanne, Suisse,\\
$^3$Instituto Superior Técnico, University of Lisbon, Portugal}

\begin{document}
\maketitle

%\begin{abstract}
%
%    Robots for education are not limited to support ICT teaching, and they are
%    indeed finding new roles in the classroom. This article reports on such a
%    new paradigm for educative robots, that involves \emph{learning by teaching}
%    and strong \emph{social engagement} to help children struggling with
%    handwriting. Our system relies on machine-learning and child-robot
%    interaction with a small humanoid robot, and we present several real-world
%    studies in schools and with occupational therapists that led us to promising
%    initial results.
%
%\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A Different Paradigm for Educative Robots}

Thomas is five and half, and has been diagnosed with visuo-constructive
deficits. He is under the care of an occupational therapist, and tries to
workaround his inability to draw letters in a consistent manner. Vincent is six
and struggles at school with his poor handwriting and even poorer
self-confidence.\footnote{All children's names have been changed.}

While Thomas is lively and always quick at shifting his attention from one
activity to another, Vincent is shy and poised. Two very different children,
facing however the same difficulty to write in a legible manner. And, hidden
beyond this impaired skill, psycho-social difficulties arise: they underperform
at school, Thomas has to go for follow-up visits every week, they both live
under the label ``requires special care''. This is a source of anxiety for the
children and for their parents alike.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{henry}
    \caption{\small Thomas teaching Nao how to write numbers, with the help of an
    occupational therapist.}
    \label{fig:henry}
\end{figure}

Remediations for handwriting difficulties traditionally involve long
interventions (at least 10 weeks~\cite{Hoy2011}), essentially consisting in
handwriting training with occupational therapists, and primarily addressing the
\emph{motor} deficits.  Improvements in self-confidence and anxiety occur (at
best) as a side-effect of the child improving their handwriting skills and,
consequently, improving their performance at school.

We present in this article a new take on this educative challenge: a remediation
procedure that involve a ``bad writer'' robot that is \emph{taught} by the
child. By building on the \emph{learning by teaching} paradigm, not only the
child practises handwriting but, as they take on the role of the teacher, they
also positively reinforce their self-esteem and motivation: their social role
shift from the ``underperformer'' to ``the one who knows and teaches''. And by
relying on a robot, we can tailor the exercises and the learning curve to each
children' needs, as we will show in this article.

\subsection{Learning by Teaching Handwriting}

The \emph{learning by teaching} paradigm, which engages the student in the act
of teaching another, has been shown to produce motivational, meta-cognitive, and
educational benefits in a range of disciplines~\cite{Rohrbeck2003}. The
application of this paradigm to handwriting intervention remains, however,
unexplored. One reason for this may be due to the requirement of an
appropriately unskilled peer for the child to tutor: this may indeed prove
difficult if the child is the lowest performer in the class.  In some cases, it
may be appropriate for a peer or teacher to simulate a na\"ive learner for the
child to teach. For handwriting however, where one's skill level is visually
evident, this acting is likely to be rapidly detected. This motivates the use of
an artificial teachable agent which can be configured for a variety of skill
levels, and for which children do not have preconceptions about its handwriting
ability.

Robots have been used as teachers or social partners to promote children's
learning in a range of contexts, most commonly related to language
skills~\cite{han2010robot}, and less often to physical skills (such as
calligraphy~\cite{Matsui2013}). Looking at the converse (humans \emph{teaching}
robots), Werfel notes in~\cite{Werfel2014} that most of the work focuses on the
robot's benefits (in terms of language~\cite{Saunders2010} or
physical~\cite{Mulling2013} skills, for example) rather than the learning
experienced by the human tutor themselves.  Our work concentrates on this latter
aspect: by demonstrating handwriting to a robot, we aim at improving the
\emph{child's} performance. Note that our work must be distinguished from
``learning from demonstration'' approaches to robots learning physical skills,
as the agent we present is only simulating fine motor skills for interaction
purposes.

A robotic learning agent which employs the learning by teaching paradigm has
previously been developed by Tanaka and Matsuzoe~\cite{Tanaka2012}. In their
system, children learn vocabulary by teaching the {\sc nao} robot to act out
verbs. The robot is tele-operated (Wizard-Of-Oz) and mimics the actions that the
children teach it, but with no long-term memory or learning algorithm in place.
Our project significantly extends this line of work in two ways. First, by
investigating the context of children's acquisition of a challenging physical
skill (handwriting), and second by proposing a robotic partner which is fully
autonomous in its learning.

\subsection{Agency and Commitment}

We also investigate here a particular role for a robot in the education of
handwriting: not only is the robot actively performing the activity by drawing
letters, but it does so in a way that engages the child in a very specific
social role. The child is the teacher in this relationship and the robot is the
learner: the child is to engage in a (meta-) cognitive relationship with the
robot to try to understand why the robot fails and how to help it best.  Here,
the robot is more than just an activity facilitator or orchestrator -- its
physical presence and embodiment induce agency and anthropomorphising, and
cognitively engage the child into the learning activity (be it consciously or
not).

The commitment of the child into the interaction build on a psychological effect
known as the ``protégé effect''~\cite{Chase2009}: the teacher feels responsible
for his student, commits to the student's success and possibly experiences
student's failure as his own failure to teach. Teachable computer-based agents
have previously been used to encourage this ``protégé effect'', wherein students
invest more effort into learning when it is for a teachable agent than for
themselves~\cite{Chase2009}.  We rely on this cognitive mechanism to reinforce
the child's commitment into the robot-mediated handwriting activity, and we
indeed show sustained child-robot engagement over extended periods of time
(several hours spread of a month).

For these two reasons, our approach is to be distinguished from previous works
in educational robotic. Most of these do not consider the agency induced by the
robot beyond its motivational aspect (playing with an interactive, partially
autonomous device naturally induces some form of anthropomorphizing, which leads
to some level of projected agency, and participate the overall excitement -- at
least, on the short-term, before the novelty effect vanishes).  In our case, the
role of agency is stronger: it induces meta-cognition (``I am interacting with
an agent, so I need to reflect on how to best teach him'') which is beneficial
for the learning process; it also induces a protégé effect (``I want my
robot-agent to succeed!'') which support the commitment of child into the
interaction, also for longer period of time.

Building on these socio-cognitive mechanisms, our intent is therefore to design
a robotic system that would effectively support handwriting remediation in an
original way: by getting children to teach a robotic agent how to write, those
children would both practise without knowing it and recover self-confidence and
self-esteem by supporting a worst-than-themselves robotic ``student''.

The following sections of the paper go into details. We first provides a brief
overview of the robotic system and the interaction it induces. We also present
the machine-learning techniques that allow the robot to learn from the children,
followed by the implementation on a {\sc nao} robot.

We then present and report on the field experiments that we have conducted over
the last two years, including four studies at school, one longer experiment with
eight children at the surgery of an occupational therapist, and two one-month
long case studies. While the focus of the school experiments was mostly the
technical validation and data acquisition, the three other experiments involved
children with actual deficits, and gave us initial insights on the relevance and
effectiveness of our approach.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation of the Interaction}

Figure~\ref{experimental_setup} illustrates our general experimental setup: a
face-to-face child-robot interaction with an autonomous Aldebran's {\sc nao}
robot.

A tactile tablet (with a custom application) is used for both the robot and the
child to write. During a typical round, the child requests the robot to write
something (a single letter, a number or a full word), and push the tablet
towards the robot. The robot writes on the tablet by gesturing the writing in
the air,  the letters being actually drawn by the tablet application itself. The
child then pull back the tablet, corrects the robot's attempt by writing
him/herself on top or next to the robot's writing (see Figure~\ref{fig:diego}),
and ``send'' his/her demonstration to the robot by pressing a small button on
the tablet. The robot ``learns'' from this demonstration and tries again.

Since the children are assumed to take on the role of the teachers, we had to
ensure they would be able to manage by themselves the turn-taking and the
overall progression of the activity (moving forwards to the next letter or
word). In our design, the turn-taking relies on the robot prompting for feedback
once it is done with its writing (through simple sentences like ``What do you
think?''), and pressing on a small robot icon on the tablet once the child has
finished correcting. In our experiments, and once introduced by the
experimenter, both were easy to grasp for all the children.


\begin{figure}
    \centering
    \includegraphics[width=0.6\columnwidth]{experimental_setup}
    \caption{\small Our experimental setup: face-to-face interaction with a {\sc
        nao} robot.  The robot writes on the tactile tablet, the child then
        corrects the robot by directly overwriting its letters on the tablet
        with a stylus. An adult (either a therapist or an experimenter,
        depending on the studies), remains next to the child to guide the work
        (prompting, turn taking, etc.). For some studies, a second tablet and an
        additional camera (dashed) are employed.}

    \label{experimental_setup}
\end{figure}

Implementing such a system raises several challenges: first, the acquisition,
analyse and learning from hand-written demonstration, which lays at the core of
the our approach, necessitates the development of several algorithms for the
robot to generate initial bad writing and to respond in an adequate manner,
showing visible (but not too quick) writing improvements.

Then, the actual implementation on the robot requires the coordination of
several modules (from performing gestures and acquiring the user's input to the
state machine implementing the high-level behaviour), spread over several
devices (the robot itself, one laptop and up to four tactile tablets for some of
the studies that we conducted). We relied on ROS to ensure the synchronization
and communication between these modules.

We detail each of these in the following sections.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Generating and Learning Letters}

Since our application is about teaching a robot to write, generating (initially
bad) letters and learning from demonstrations is a core aspect of the project.

The main insight for both the generation and the learning of letters is to
reason about the shape of letters in their eigenspace, instead of the natural
cartesian space. The eigenspace of each letters is spanned by the first $n$
eigenvectors (in our experiments, $3 < n < 6$) of the covariance matrix
generated from a standard dataset of adult letters (the UJI Pen Characters 2
dataset~\cite{Llorens2008}).  This procedure, based on a Principle Component
Analysis (PCA), is explained in details in a previously published
article~\cite{hood2015when}.

By changing the eigenvalues associated to these eigenvectors and regenerating
letters with the reverse procedure, it becomes then easy to generate new
letters, with distortions that are actually plausible handwriting errors: they
are exaggerations of variance of writing styles that naturally occurs amongst
adult writers.  Figure~\ref{fig:sampleLetters} shows examples of deformed ``g''
generated with such a technique.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{cowriter-g}
    \caption{\small \label{fig:sampleLetters} \textbf{Generating bad letters}:
        effect of varying the first five eigenvalues (rows) of the shape model
        of ``g'' by different factors (columns). The percentage of the total
        variance in the dataset explained by each eigenvalue is shown      on
        the appropriate row. Examples noted A, B, C, D illustrate how the
        PCA-based approach allows to \emph{automatically} generate letters whose
        errors can be \emph{semantically} interpreted, \eg A has a too large bottom
        loop, B has a wide top loop, the bottom loop of C is not correctly
        closed, the top loop of D is not closed, etc.}

\end{figure}

The same technique can also be applied to \emph{classify} demonstrations,
\emph{assess} their quality and \emph{learn} from them. Figure~\ref{fig:h} shows
for example nine allographs of ``h'' written by a 6 years old child, along with
the mean letter from the dataset (reference letter). By projecting each of the
demonstrations onto the eigenspace of ``h'' (Figure~\ref{fig:h}b), we observe
that:

\begin{itemize}
    \item the different allographs can by clustered (with a $k$-means or
        mean-shift algorithm) by their visual styles,

    \item we can compute an euclidian distance to the reference letter to assess
        the topological proximity of the demonstration with the expected letter,
        thus providing a quantitative metric of writing performance.

\end{itemize}

\begin{figure}[ht!]
    \centering
    \subfigure[Nine allographs of the cursive ``h'', next to the reference]{
        \includegraphics[width=0.45\columnwidth]{h}
    }
    \subfigure[Same samples, normalized and projected in the eigenspace spanned from the
        3 first eigenvectors: clusters arise, that actually match writing styles.]{
        \includegraphics[width=0.45\columnwidth]{eigenspace-uniformization}
    }

    \caption{\small Projecting demonstrated letters onto the eigenspace
    generated from the reference dataset effectively clusters the samples
    according to their topological similarity. Allographs that are similar to
    the reference are close to it in the eigenspace.}
    \label{fig:h}
\end{figure}

The algorithm for machine-learning becomes then a simple matter of converging at
a specific pace towards the child demonstration in the eigenspace.
Figure~\ref{learning_6_demos} (p.~\pageref{learning_6_demos}) illustrates the
process with a complete learning cycle of the number ``6''.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Robotic Implementation}

Our system is embodied in an Aldebaran's {\sc nao} (V4 or V5, depending on the
studies) humanoid robot. This choice is motivated by its approachable
design~\cite{Gouaillier2008}, its size (58cm) and inherently safe structure
(lightweight plastic) making it suitable for close interaction with children,
its low price (making it closer to what school may afford in the coming years)
and finally its ease of deployment on the field.

Robotic handwriting requires precise closed-loop control of the arm and hand
motion. Because of the limited fine motor skills possible with such an
affordable robot, in addition to the absence of force feedback, we have opted
for \emph{simulated handwriting}: the robot draws letters in the air, and the
actual writing is displayed on a synchronised tablet.

\begin{figure}[ht!]
\centering

\resizebox{0.7\linewidth}{!}{%

\begin{tikzpicture}[
    >=latex,
    node distance=2cm,
    every edge/.style={draw, very thick},
    redarrow/.style={draw,red, text=black},
    greenarrow/.style={draw,GreenYellow,text=black},
    yellowarrow/.style={draw,BurntOrange,text=black},
    cmpt/.style={draw, align=center, rounded corners, inner sep=5pt, font=\sf, fill=black!20},
    label/.style={midway, align=left, font=\scriptsize\sf, fill=white, above,opacity=0,text opacity=1}]

    \node at (0,0) (laptop) {\includegraphics[width=2cm]{laptop}};
    \node[below right=2 of laptop] (nao) {\includegraphics[width=2cm]{nao}};
    \node[below left=2 of laptop] (tablet) {\includegraphics[width=2cm]{tablet+stylus}};
    \node[above=2 of laptop] (selection) {\includegraphics[width=2cm]{selection_tablet}};

    \node[draw,above right=2 of laptop,anchor=north west,text width=4cm] (processes)
    {\sf\scriptsize machine-learning, \\letters/gestures
    generation, \\interaction supervision};
    \path (laptop) edge[dashed] (processes);

    \path (nao) edge [->,redarrow, bend left] node[label, auto] {robot state} (laptop);
    \path (laptop) edge [->,greenarrow, bend left] node[label, auto] {writing gestures} (nao);

    \path (tablet) edge [->,redarrow, bend left] node[label, auto] {demonstrations,\\turn taking} (laptop);
    \path (laptop) edge [->,redarrow, bend left] node[label,
    auto=right,align=right]
    {path of\\ letters to display} (tablet);

    \path (selection) edge [->,redarrow] node[label, auto=right] {letter/word to write} (laptop);

    \path (-5, 2) edge [->, redarrow] node[label] {ROS} ++(1, 0);
    \path (-5, 2.6) edge [->, greenarrow] node[label] {NaoQI} ++(1, 0);
    
\end{tikzpicture}
}

\caption{\small \textbf{Overview of the system}. In total, the system runs about 10 ROS nodes,
    distributed over the robot itself, a central laptop and Android tablets.}

    \label{fig:archi}
\end{figure}

The overall architecture of the system (Figure~\ref{fig:archi}) is therefore
spread over several devices: the {\sc nao} robot itself, that we address via
both a ROS API\footnote{The ROS documentation for {\sc nao} is available at
\url{http://wiki.ros.org/nao}.} and the Aldebaran-provided NaoQI API, one to
four Android tablets (the main tablet is used to draw the robot's letter and to
acquire the children's demonstrations; more tablets have been used in some
studies, either to let the child input words to be written, or for the
experimenter to qualitatively annotate the interaction in a synchronized
fashion), and a central laptop running the machine learning algorithms, the
robot's handwriting gesture generation (based on the NaoQI inverse kinematics
library) and the high-level control of the activity (relying on {\sc
pyRobots}~\cite{lemaignan2015pyrobots} and a custom finite state machine).

Since the system does not actually require any CPU-intensive process, the laptop
can be removed and the whole logic run on the robot. Due to the relative
difficulty to deploy and debug ROS nodes directly on the robot, the laptop
remains however convenient during the development phase and we kept it during
our experiments.

Most of the nodes are written in Python, and the whole source code of the
project is available online\footnote{The primary repository is
\url{https://github.com/chili-epfl/cowriter_letter_learning}.}. The details of
the technical implementation are available in~\cite{hood2015when}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Field Studies}

The system has been deployed and tested in several situations: in three
different schools (more than 70 children aged 5 to 8; relatively short duration
interactions), in the surgery of an occupational therapist (8 children; each
interacting several hours with the system), and during two case studies that
each lasted several weeks. Table~\ref{studies} gives an overview of these
studies.

\begin{table}[ht!]
\centering
\caption{\small Field studies conducted within the project}
\label{studies}
\footnotesize
\begin{tabular}{@{}lp{4cm}p{2.2cm}p{2cm}l@{}}
\toprule
{\bf Study}        & {\bf Type}                               & {\bf Avg. duration}    & {\bf \# Children}                     & {\bf Ages} \\ \midrule
{\it School A (1)} & Unstructured group interaction at school & 16 min/group           & 4 $\times$ 8 children                 & 6-7        \\
{\it School B}     & Individual/Pair interaction at school    & 11 min/group           & 7 (individual) + 7 $\times$ 2 (pairs) & 7-8        \\
{\it School C}     & Pair interaction at school               & 26 min/group           & 7 $\times$ 2                          & 5-6        \\
{\it School A (2)} & Individual interaction at school         & 20 min                 & 6                                     & 5-6        \\ \midrule
{\it Surgery}      & Individual interaction at surgery        & 3 sessions $\times$ 1h & 8                                     & 6-8        \\ \midrule 
{\it Vincent}      & Case-study                               & 4 weeks $\times$ 1.5h  & 1                                     & 6          \\
{\it Thomas}       & Case-study                               & 4 weeks $\times$ 1h    & 1                                     & 5          \\ \bottomrule
\end{tabular}
\end{table}

We report hereafter the main design choices and results for each of these
studies and experiments. The interested reader can find supplementary details
in~\cite{jacq2016building, hood2015when}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{System Validation at Schools}

Over the two years of the project, we conducted four studies in schools
(Figure~\ref{fig:schools}). These experiments were meant to technically validate
the system (is it actually able to autonomously write and learn from
demonstrations?) and test the interaction (is the apparatus easy to grasp and to
interact with for children?). We also studied the initial acceptance of the
robot in the school environment (through several formal and informal discussions
with teachers) and how children engage with the robot (and maintain or not this
engagement).

\begin{figure}
    \centering
    \includegraphics[height=3.9cm]{schools}
    \includegraphics[height=3.9cm]{schools2}
    \caption{\small The first field studies were focused on technical validation, with
    more than 70 pupils interacting with the robot over short periods (between
    10 and 25 minutes), either alone or in small groups.}
    \label{fig:schools}
\end{figure}

Critically, these studies were conducted with \emph{whole classes}: we decided
not to select specifically underperforming children as having more children (73
in total) was beneficial for these preliminary studies. Besides, due to ethical
concerns, this would have required complex organization with the school that we
wanted to avoid at the validation stage.

\paragraph{System validation}

From a technical perspective, the system achieves an acceptable level of
reliability and allow a technically sound autonomous interaction. For instance,
during the second school study (\textit{School B}), the robot withstood
interactions which lasted for a total of 160 minutes.  During this time the
robot wrote 335 letters, 152 of which in response to demonstrations received
from the 21 children. Technical intervention was only required for the three
instances that the robot fell during that day.  Otherwise, the technical
components of the system operated autonomously and as expected with all the
groups of children.

Due to the modular software architecture (mostly independent ROS nodes), the
occasional crashes occurring during others studies were usually quickly resolved
by re-launching the faulty node alone, and did not significantly impact the
interaction.

The otherwise technical limitations were related to some letters or writing
style (most notably, the ones requiring multiple strokes per letter) not being
adequately processed by the learning algorithm. Support for such letters was
added as a follow-up of the validation studies.

\paragraph{Acceptance}

Children's recognition that the robot is writing by itself is critical for our
approach to be effective. When asked, no child indicated that they did not
believe that the robot was writing by itself. There were, at times, questions
about the robot's writing method at the beginning of the interaction, but when
advised that the robot ``tells the tablet what it wants to write,'' this was
accepted by the children.  Besides, teachers interviewed for their feedback on
the system advised that children are asked to draw letters in the air in a
similar manner as part of their handwriting education. The behaviour is hence
not unfamiliar to children.

During two focus groups organized with teachers, the welcomed the approach and
recognized it as useful and promising; this was \textit{a posteriori} confirmed
by multiple spontaneous contacts made by parents and therapists who were looking
forward to use the system with their children.

\paragraph{Sustained engagement}

The literature suggests that 20 handwriting practice sessions is found to be the
minimum to demonstrate effective results in handwriting
remediation~\cite{Hoy2011}. This highlights the necessity to sustain a
child-robot engagement over the long-term if we want to achieve measurable
learning gains.

Factually, the children engaged into the teaching activity: in the
\textit{School B} study, for instance, they demonstrated an average of 10.9
demonstration letters (SD = 4.4) for an average session duration of 11 minutes.
In 9 out of the 14 sessions (64\%), the robot received demonstration letters
even \emph{after} reaching the final stage of the interaction, suggesting an
intrinsic motivation to further engage in the interaction.

%\begin{figure}[ht!]
%    \centering
%    \includegraphics[width=0.9\linewidth]{engagement}
%    \caption{\small Engagement level of one child, manually annotated by two judges
%        over a 13 min long interaction (Cronbach’s alpha test: $\alpha = .82$,
%        good inter-judge agreement). 0 means ``complete disengagement from the
%        task'', 6 means ``full engagement''. The vertical lines represent activity
%    switches between handwriting teaching and story-telling (used as a
%    disturber).}
%    \label{engagement_level}
%\end{figure}

\begin{table}[h!]
    \centering
    \caption{\textbf{Levels of with-me-ness}. Percentage of interaction time
        during which the child was effectively focusing his/her attention on the
        task. The six children are those from the second study at School A.
        Interaction duration: M = 19.6 min, SD = 1.58. Results
        taken from~\cite{lemaignan2016realtime}.}

    \begin{tabular}{p{1cm}cccccccc}
        \toprule
        \bf Child & 1 & 2 & 3 & 4 & 5 & 6 & {\bf M} & {\it SD} \\
        \midrule
        $\mathcal{W}$ & 79.4\% & 81.6\%  & 90.5\% & 87.9\% & 90.7\% & 80.9\% & {\bf 85.2\%} & {\it 5.1} \\ 
        \bottomrule
    \end{tabular}
    \label{tab:results-with-me-ness}
\end{table}

We also conducted a quantitative assessment of the engagement levels of the
children. Table~\ref{tab:results-with-me-ness} reports the levels of
\emph{with-me-ness} of the children during the second study at school A.
\emph{With-me-ness} is a quantifiable precursor of engagement: it measures the
percentage of time spent by the child focusing onto the task at end. This metric
was first devised in the context of computer-supported
learning~\cite{sharma2014me}, and we have previously studied its applicability
to human-robot interaction and formalized the exact methodology
in~\cite{lemaignan2016realtime}\footnote{Note that with-me-ness is a metric that
allows real-time computation by the robot itself: while we did not yet make
use of it, it does in principle allow the robot to detect on-line possible
disengagements, and eventually address them by adapting its physical
behaviour, switching to different activities, etc.}.

The average with-me-ness is well above 80\%, and confirms that the children
where very much engaged into these 20 minutes of interaction with the robot,
paying close attention to the task.

The other three experiments (the group study at the surgery and the two
case-studies) provide further qualitative evidence of engagement over longer
interaction periods. In particular, as reported hereafter, the two 4-weeks long
case studies that have been conducted so far show that our system can sustain
children' engagement over durations (5 hours) that are getting closer to what is
expected to have an impact in a real therapeutic context.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Surgery Study: How Children Take on the Role of a Teacher}\label{normandie}

\paragraph{Context, Study Design}

\begin{inparaenum}[\itshape 1\upshape)]
This experiment was conducted to study \item how easily children with actual
deficits take on the role of a teacher, and \item if they engage
\emph{seriously} in this role. Measuring actual handwriting improvements was
not a primary goal of this experiment.
\end{inparaenum}

The experiment took place at the surgery of an occupational therapist in
Normandy, France. Eight children participated, selected by the occupational
therapist based on their age and type of deficit (all related to handwriting).
Valérie (female, 7 years old), Antoine (male, 6.5) and Johan (male, 7) are under
the direct care of the occupational therapist. Émilien (male, 8) and Mathieu
(male, 7) are repeating their school year because of writing difficulties. Marie
(female, 6) and Adèle (female, 8) are both ranked at the bottom of their
respective classes in writing activities. Nicolas (male, 7) is under the care of
a neurologist, and has been diagnosed with specific language impairment. Given
their age and school year, all those children would be expected to know how to
correctly shape cursive letters. 

Over a period of two weeks, each child attended three time a one hour long
session (except for Marie and Adèle who only attended one session). The
experimenter role was limited to the explanation of the task and the basic
tablet usage. For this experiment, the children were provided with two tablets:
one to choose the words (or letters) to teach to the robot, the other one to
write, like in the validation studies. We also provided paper-based templates of
the cursive letters, where the children to ask for them.

We only provided the children with minimal explanations on the task (they would
have to help the robot to improve its writing style), so as to assess if and how
children would naturally take on the role of the teacher. We besides assessed
how seriously they engage into helping the robot through two additional buttons
on the tablet: a green ``thumbs up'' and a red ``thumbs down''. The children
were told to freely use them to evaluate the robot's improvements (``thumb up''
to give positive feedback, ``thumb down'' to convey negative feedback). Our
assessment builds on the hypothesis that the more the child provides feedback to
the robot, the more they assume the role of a teacher. Then, by correlating the
feedback with the actual performance of the robot, we can measure to what extend
the children are seriously assuming their role: if their feedback does correlate
with the actual performance of the robot, the child is likely engaged into a
\emph{serious} teaching role-playing.


\paragraph{Results}

\begin{table}
    \centering
    \begin{tabular}{ccccl}
        \toprule
        \bf Child      & \bf \# Demos/hour & \bf \# Positive & \bf \# Negative & $r$ \\ \midrule
        \emph{Valérie} & 42           & 24              & 6               & 0.25 \small\tt **  \\ 
        \emph{Émilien} & 74           & 20              & 9               & 0.06 \small\it ns  \\
        \emph{Mathieu} & 43           & 10              & 3               & 0.23 \small\tt **  \\
        \emph{Nicolas} & 38           & 16              & 4               & 0.31 \small\tt *** \\
        \emph{Johan}   & 32           & 10              & 5               & 0.10 \small\it ns  \\
        \emph{Antoine} & 27           & 10              & 3               & 0.20 \small\tt *   \\
        \emph{Adèle}   & 35           & 4               & 2               & 0.28 \small\tt *   \\
        \emph{Marie}   & 40           & 5               & 1               & -0.02 \small\it ns \\ \bottomrule
    \end{tabular}
    \caption{\small Feedback from the children to the robot. \emph{\#Demos}
        denotes the average number of demonstrations per hour provided by the children;
        \emph{\#Positive} and \emph{\#Negative} the total number of positive \resp
        negative feedbacks they provided. $r$ is the correlation coefficient
        between the feedback provided by the children and the performance of the
        robot. Results taken from~\cite{jacq2016building}.}

    \label{table:scores}
\end{table}

All children maintained their engagement during the entire sessions. They
provided on average 42 demonstrations per session. All children did use the
feedback buttons (in total, 99 ``thumb up'' and 33 ``thumb down'' were recorded,
see Table~\ref{table:scores}). This indicates that they are all able to engage
into playing the role of a teacher.

To study the correlation between the children' feedback and the actual
improvements of the robot, we estimate the robot's progress as the difference
between an initial score (average euclidian distance between the shape drawn by
the robot at its first attempt and the shape of the reference letter) and the
robot's score at the current round of demonstrations. We then correlate this
progress to the positive or negative feedback provided by the children (details
of the method are presented in~\cite{jacq2016building}).

We find that the feedback of five out of the eight children do significantly
correlate with the actual performance of the robot (Table~\ref{table:scores}).
This indicates that these children are effectively taking on the teacher's
clothes and are seriously providing feedback to the robot. The observation of
the three remaining children reveal a variety of behaviours (for instance, one
was actually rating how ``nice'' the robot is, and another one had rather
``artistic'' writing style preferences that were independent of the actual
legibility of the robot), and during this specific experiment, we eventually
found that they were all seriously engaged into teaching.

To summarize, this experiment shows that children with actual handwriting
impairments do accept well the robot, can commit themselves into long
interactions, do take on the role of the teacher (as evidenced by both the
number of writing demonstrations they provided and their self-inclination to
give feedback to the robot), and finally take their teacher's role seriously.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Case Study 1: Vincent}

\paragraph{Context, Study Design}

For the first case study, we invited and followed Vincent, a six years old
child, once per week over a period of a month. Our primary aim was to address
the question of whether we can sustain Vincent's engagement and commitment to
the writing activity over such a period.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{diego}
    \caption{\small Vincent correcting {\sc nao}'s attempt by rewriting the
        whole word. Empty boxes are drawn on the screen to serve as template for the child
        and to make letter segmentation more robust.}
    \label{fig:diego}
\end{figure}

The study took place at our laboratory (Figure~\ref{fig:diego}), and we chose to
design the activity around a storyline meant to be attractive for a 6 years old
boy: one of our {\sc nao} was away for a mysterious scientific mission, and it
needed the support of another one -- which would remain at the lab -- to
interpret curious pictures that were sent every week. Vincent had to help the
second robot understanding the pictures, and since the two robots had somehow
beforehand agreed to communicate with ``letters written like humans'' (\ie
handwritten), Vincent also had to help the robot to write good looking letters
(because, well, this robot was terrible at writing!) The experimental setup was
similar to Figure~\ref{experimental_setup}, except that Vincent had to tell the
robot what to write with small plastic letters (visible behind the robot on
Figure~\ref{fig:diego}).

To supplement the intrinsic motivation of helping a robot to communicate with
another one, we gradually increased the complexity of Vincent's task to keep it
challenging and interesting (the first week: demonstration of single letters;
the second week: short words; the third week: a full letter --
Figure~\ref{fig:stimuli}).

The last session was set as a test: the ``explorer'' robot had come back from
its mission and it actually challenged the other robot in front of Vincent:
\emph{``I don't believe you wrote yourself these nice letters that I received!
Prove it to me by writing something in front of me!''} This situation was meant
to evidence the Protégé effect: by judging the other robot's handwriting, the
``explorer'' robot would implicitly judge Vincent's skills as teacher, and in
turn, Vincent's handwriting.

\paragraph{Results}

\begin{figure}
    \centering
    \subfigure[Initial text, generated by the robot]{
        \includegraphics[height=6cm]{diego-initial-letter}
    }
    \subfigure[Final text, after training with Vincent]{
        \includegraphics[height=6cm]{diego-final-letter}
    }

    \caption{\small Text (in French) generated by the robot, before and after a one
        hour long interaction session with the child. The red box
        highlights one instance of striking improvement of the robot's
        handwriting legibility.}

    \label{fig:stimuli}
\end{figure}

Over the whole duration of the study, Vincent had provided 154 demonstrations to
the robot, and he remained actively engaged over the four weeks. The story was
well accepted by the child and he seriously engaged into the game. After the
first week, he showed good confidence to play with the robot and by the end of
the study he had built affective bonds with the robot, as evidenced by several
letters he did send to the robot \emph{after} the end of the study (one of them
four months later) to get news. This represents an initial validation of our
hypothesis: our system can effectively keep a child engaged with the robot for a
relatively long period of time (about 5 hours spread over a month), and we can
build a tutor/protégé relationship.

No hard conclusion can be drawn in terms of actual handwriting remediation as we
did not design this study to formally assess possible improvements. However, as
visible on Figure~\ref{fig:stimuli}, Vincent was able to significantly improve
the robot's skill, and  he acknowledged that he was the one helping the robot
during post-hoc interviews. In that respect, Vincent realized that he was ``good
enough'' at writing to help someone else. The fact that Vincent seriously
committed to the role of a teacher is further supported by feedback sent by
Vincent's parents a week after the end of the experiment: ``Vincent's
handwriting has changed over the last weeks, going from a mix of standalone and
cursive letters to full words in cursive. This requires a lot of efforts and
concentration from him, but he did succeed during the sessions with the robot as
he knew he had to show a consistent writing to the robot''.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Case Study 2: Thomas}

\paragraph{Context, Study Design}

The second long-term study was designed in collaboration with an occupational
therapist in Geneva, and aimed at deploying the system on the longer-term with a
real therapeutic case.

Thomas is a 5.5 years old child. He has been diagnosed with visuo-constructive
deficits, which translate into difficulties for him to consistently draw
letters. Besides, focusing on a task is difficult for Thomas, who tends to
rapidly shift his attention to other things. Since the robot's learning
algorithm requires repeated demonstrations of similarly shaped letters to
converge, the occupational therapist was especially interested in observing if
the robot would induce a strong enough motivation for Thomas to focus on
producing many regular, consistent letters, thus overcoming his deficit.

The experiment took place at the therapist's surgery (four sessions spreading
over 5 weeks). Contrary to Vincent's experiment, we chose not to introduce any
backstory beyond a simple prompt (``the robot wants to participate to a robotic
handwriting contest, will you help him to prepare?'') only provided during the
first session. Hence, we also tested during this case-study if the robot (and
the Protégé effect) would induce by itself a strong enough intrinsic motivation
to keep the child engaged over the five weeks.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{learning_6_demos}

    \vspace{1em}

    \includegraphics[width=0.7\linewidth]{learning_6_distances}
    \caption{\small Demonstrations provided by Thomas for the number ``6'' (top
        row) and corresponding shapes generated by the robot. The plot beneath
        shows the distance to the reference shape (in the eigenspace of the
        shape) to Thomas' demonstrations, and to the robot's attempts. After
        eight demonstrations, Thomas decided that the robot's ``6'' was good
        enough, and switched to another character. In that respect, he was the
        one leading the learning process of the robot.}

    \label{learning_6_demos}
\end{figure}


The occupational therapist had recently carried activities with Thomas about
writing numbers, so we decided with her to focus on these as well: Thomas would
use a secondary tablet to tell the robot what number to write, and would then
correct the robot's attempts like in the other experiments.
Figure~\ref{learning_6_demos} shows the attempts/corrections cycles that
occurred during one of the session, on the number ``6''.

%Before the experiment, Thomas was working on writing numbers with the therapist.
%Hence we decided to turn the CoWriter activity to teach numbers to the robot.
%Build on existing iPad applications actually used by occupational therapists
%(Dawson Toth's \emph{ABC's Writer}), we designed an Android application for
%pre-test and post-test. It consisted in drawing numbers following an helping
%pattern, that becomes more fine with levels in order to increase
%difficulty~\ref{fig:abc-writer}.

Since Thomas would frequently draw mirrored numbers, or hard-to-recognize shapes
(see Figure~\ref{Thomas_progress}), the learning algorithm of the robot
initially tended to converge towards meaningless scribblings. We addressed this
issue by having the robot to \emph{refuse} allographs that were too far from the
reference shape (the robot would instead say \emph{``I'm not sure to understand
what you are drawing...''}), so that the child had to pay good attention to what
he would demonstrate to the robot. Also, to make the robot's progress evident,
we modified the initialization step of the learning algorithm to start with a
roughly vertical stroke instead of a deformed number (see the initial state on
Figure~\ref{learning_6_demos}).

%\begin{figure}
%    \centering
%    \includegraphics[width=0.9\linewidth]{abc-writer}
%    \caption{\small Screenshot of the Android application developed to be used as
%    pre-test and post-test: the child must follow with his finger the path of
%the letter or number. We count the number of times the finger goes outside of
%the red-bordered area.}
%    \label{fig:abc-writer}
%\end{figure}
%

\paragraph{Results}

Despite his attention deficit, Thomas was able to remain engaged in the activity
during more than forty minutes in each session (a long time for a five years
old). In total, 55 allographs out of 82 demonstrated by the child were
acceptable considering our threshold (with a progressive improvement from 13 out
of 28 in the first session up to 26 out of 29 in the last session).

As soon as Thomas understood that the robot was only accepting well-formed
allographs, he started to focus on it and he would typically draw 5 or 6 times
the number before actually sending to the robot (the tablet lets children clear
their drawing and try again before sending it). According to the therapist, it
was the first time that Thomas was seen to correct himself in such a way,
explicitly having to reflect on how \emph{another agent} (the robot) would
interpret and understand his writing. Figure~\ref{Thomas_progress} shows how he
gradually improved his demonstrations for two different numbers.

Since the robot's handwriting started from a simple primitive (a stroke), each
time Thomas succeeded in having his demonstration accepted by it, the robot's
improvement was clearly visible (as shown in Figure~\ref{learning_6_demos}).
This led to a self-rewarding situation that effectively supported Thomas'
engagement.

\begin{figure}
    \centering
    \subfigure[Number ``2'']{
        \includegraphics[width=0.45\linewidth]{henry2}
    }
	\subfigure[Number ``5'']{
        \includegraphics[width=0.45\linewidth]{henry5}
    }
    \caption{\small Normalized distance between Thomas' demonstrations and
        reference allographs for the numbers ``2'' and ``5''. The horizontal
        dashed line correspond to the threshold for the robot to accept a
        demonstration. Thomas' progress is visible on these figures: we find a
        significant negative regression equation ($r=-0.023, F(1,19)=8.69,
        p<.02$, adjusted $R^2=.461$) for the number ``2'' (dotted red line),
        indicating that Thomas' shapes are getting closer to the reference. The
        regression is not significant for the number ``5'', but we can observe
        that after about 10 repetitions, all the demonstrations are deemed of
        acceptable quality by the robot.  }

    \label{Thomas_progress}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary of the Findings and Discussion}

The four school studies, the experiment at the surgery and the two case-studies
provide a first broad picture of how a robot-based remediation to handwriting is
accepted by the children and practitioners, and what outcomes can be expected.

In total, more than 80 children have interacted with the system, for a total
duration of more than 38 hours, in multiple experimental configurations
(individual interaction \vs pairs \vs groups; at school, in the lab, at a
surgery; short interactions \vs long, repeated interactions; 5 to 8 years old
children). We summarize hereafter the main findings from these experiments and
discuss some of the critical points of our approach.

\paragraph{Technical Assessment} We set ourselves the challenge of developing an
autonomous robotic system able to perform handwriting tasks with children.
Over the course of the different studies and experiments, thousands of
letters have been indeed generated and drawn on the tactile tablet by the robot, in
response to thousands of demonstrations from children. Most of the experiments have been
carried out in the wild, at six different locations in total. As reported in the
technical studies section, the system performed generally well: the children had no
issues interacting with the robot, the robot experienced relatively few crashes,
and those crashes did not significantly impaired the interactions. The system
has furthermore proved robust enough to conduct several hour-long experiments.
However, we also found that the level of expertise required to deploy and
operate our system still makes the presence of an experimenter mandatory at all
time. Non-trivial technical developments may be required to reach a level of
usability suitable for a broader, non-expert, audience.

\paragraph{Acceptance} When we started the project, the mere acceptance of the
robot in the educative and/or medical context of handwriting remediation was not
obvious. Expectedly, the attitude of practitioners toward the robot indeed
varies a lot at individual levels. The process that led us to select the schools
and surgeries for the experiments is interesting in that regard. The very first
school we contacted was a local public school. The head teacher was positive
about the study, but did ask for official agreement, which never happened. As we
learnt several months later, the request was still laying on the desk of a
regional education officer who happens not to be too keen on novel technologies.
Conversely, the three schools where we did conduct the first studies are all
private schools, generally open to novel learning methods. The teachers we met
during these experiments certainly had questions about the rationale and
end-purpose of the project, but were confident about its educative and social
value.

Similarly with the occupational therapists: while Thomas' therapist did
voluntarily contacted us (after hearing about the project at the radio) and
readily involved herself in the design of the experiment with Thomas, we had
less positive feedback from other practitioners: in one instance, we contacted
ourselves a local group of school psychologists and occupational therapists to
present the project: after the meeting, the opinions were definitively mixed,
with some therapists willing to conduct actual experiments with their children,
and others not quite as enthusiastic.

Lastly (and as expected), the reaction of the children to the robot was good:
they enjoyed interacting with the system, and, as we have shown, they actually
committed to their teacher role. The teaching situation was well accepted: while
we had initial doubts about how believable a learner the robot would be, the
children did not appear to show any specific issues with it. In particular,
technical choices like having the robot to only gesture writing on the tablet
instead of actually \emph{physically} writing with a pen, were not raised as
issues.

\paragraph{Engagement} We measured the engagement of the children by three
different means: the number of demonstrations they provided to the robot, the
amount of qualitative feedback they gave to the robot (in the \emph{Surgery}
experiment), and to what extend they were focusing on the task (measure of the
with-me-ness). Independently of the experimental setting, it appears that the
children engage easily into the interaction. More interestingly, we show in the
\emph{Surgery} experiment that they generally take on the role of a teacher
easily, that they act this role seriously (and not only playfully), and that
they can assume this role over an extended period of time. Designing a system
that keeps children engaged over several hours is especially important for
handwriting remediation, and we show in the case-studies that even children as
young as 5.5 years old like Thomas were able to do so. This seems to indicate
that our approach could be relevant for a broad range of ages.

Another finding relates to the Protégé effect: as seen with Vincent's case-study
(with the parents emphasizing how Vincent was aware he had to be consistent in
his writing to help the robot, or with him sending us a mail several months
later to know how the robot was doing with its writing) or with Thomas's
case-study (when Thomas realizes that the robot ``does not understand'' when his
demonstrations are not legible enough, and consequently quickly improves his
own writing to better help the robot), our system does seem to elicit a Protégé
effect that not only help the children to remain engaged into their teaching
over several weeks, but also positively impact their learning process (Vincent
strives to write in a consistent manner, as does Thomas). This supports {\it a
posteriori} our choice to build an interaction situation based on the
\emph{learning by teaching} paradigm.

\paragraph{Remediation Efficacy} Vincent's case study did provide us with
initial material to evidence handwriting improvements (Figure~\ref{fig:stimuli})
and the study with Thomas provide further data, both quantitative
(Figure~\ref{Thomas_progress}) and qualitative (feedback from the therapist that
points how Thomas is much better at drawing consistent shapes in a repeated manner,
as well as reflecting on his own performance by training several times before
actually sending a demonstration to the robot).

We must however remain cautious here as for the actual role of the system: while
the children were indeed the one deciding what to teach to the robot and the
robot was autonomously learning and responding, the role of the adults (the
experimenters or the occupational therapists) should not be underestimated.
Beyond the normal explanations on how to operate the tablet and how to interact
with the robot, the adults played the role of a facilitator in every of the
studies by prompting the children to comment on the robot's performance,
suggesting possible corrections, or proposing to try another letter/number/word.
This facilitation not only compensates for the possible shortcomings of the interaction,
but is also a fundamental part of the learning process itself. In that respect,
our robot is essentially a tool that creates a favourable learning situation for
the child, and where the adult (be it a teacher or a therapist) keeps its entire
educative role.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

We believe that this research provides a novel perspective on educative robots
at several levels. We have shown that:

\begin{itemize}
    \item robots in an educative context are certainly \textbf{relevant and
        effective beyond STEM} (Science, Technology, Engineering and
        Mathematics) \textbf{teaching},

    \item we can successfully \textbf{transpose the well-established
        \emph{learning by teaching} paradigm} from education sciences to
        robotics, even in a \textbf{complex form}: handwriting is difficult
        physical skill, the robot learns and interact autonomously, the child is
        responsible not only for the teaching but also for the teaching
        orchestration by managing the turn taking and the progression of the
        activity,

    \item blending machine-learning techniques with human-robot interaction
        allows for building a \textbf{believable agent}, that induces
        \textbf{social commitment},

    \item this proves essential to \textbf{sustain a long-term interaction}
        (several hours) although the task would be typically considered as
        repetitive yet challenging by the children,

    \item besides, the social commitment induces a \textbf{cognitive engagement}
        of the child with the robot, which is \textbf{a key learning lever} as its
        elicits \textbf{reflective, meta-cognitive mechanisms on the learning task}.

\end{itemize}

As we show through extensive experimental validation, these claims are not just
words: we have effectively deployed robots on the field, with children suffering
actual handwriting impairments. Our results are promising in terms of sustaining
the interest and attention of children on otherwise repetitive writing exercises,
and we evidence handwriting improvements.

It is however still early to quantify the lasting effects of this remediation:
handwriting is a complex cognitive skill, that builds on many individual and
social factors. Self-confidence is one of them. Our approach endows the child
with the role of a teacher who can help a robot: we expect it may as well help
some children to recover self-esteem and self-confidence by putting them in a
positive, gratifying role. The experiments that we have conducted so far do not
allow us to confirm this hypothesis yet, and more research will have to be
conducted in this direction.


\paragraph{Possible Ethical Concerns} Two aspects of this research ought to be
discussed in terms of their possible ethical implications: the perceived role of
the robot \textit{vis-à-vis} the real teachers, and the implications of the
mentor-protégé relationship for children, especially vulnerable ones.

The place and role of the robot \textit{vis-à-vis} the teacher can be
questioned: as we see it, the role of the robot within the classroom (or at the
therapist's surgery) does not infringe upon the role of the adult (teacher or
therapist). The core of the \emph{learning by teaching} paradigm relies on the
child becoming the teacher of an underperforming pupil (the robot): from that
perspective, the robot does not replace the teacher, on the contrary. It plays a
different role in the classroom, which happen to be novel as well: the robot is
the \emph{least} performing student, and still a very patient, always eager to
improve, one.

The importance of the adult is further supported by our experiments: even with
an autonomous, nominally performing robot, to put the teacher's clothes on
remains (expectedly) difficult for 5-6 years old children, and during the
experiments we conducted, the adult always played a key role at prompting the
child to give feedback to the robot or to move to the next letter or word.  At a
higher orchestration level (and as reported in the two case studies with Vincent
and Thomas), the educational scenarios were also always designed and monitored
by the adults.

We initially envisioned our system to be run in the back of a classroom with one
child: this would have allowed an individual, face-to-face remediation approach,
not otherwise tractable for a teacher with 20 pupils.  This is however unlikely
to happen soon. In our experience, the teacher keeps such an important role that
the interaction (and the learning!) would hardly occur if the child is left
alone (or even semi-alone). We can therefore reassure teachers: robots are not
going to replace them any time soon, and the initial feedback that we received
during the focus groups shows that, once explained, our approach make sense and
is indeed welcomed by the teachers themselves.

The implication of the mentor-protégé relationship on the children is less
clearly understood. We have certainly seen that the children can establish
strong affective bonds with the robot (as witnessed for instance by the letter
sent by Vincent several months after he interacted with the robot), but we are
not yet able to precisely characterize these bonds. The ethical implications of
the mentor-protégé relationship have been explored before in the context of
human teaching~\cite{brad1999mentor,wendelyn2008context}, but they mostly looked
at the question from the perspective of the protégé, whereas in our case, the
child is the mentor. As such, relatively little is known on the psychological
implications for a child to commit in helping a robot, and as advocated by
Belpaeme and Morse~\cite{belpaeme2010time}, we likely need to first gain more
field experience before being able to draw conclusions.

Beyond handwriting, we however do believe that this work provides a novel
perspective on the role for robots in the field of education. \emph{Learning by
teaching} is a powerful paradigm because of not only its pedagogical efficacy,
but its potential to positively impact the child's motivation and self-esteem.
While we need to carefully clear up the possible ethical concerns, we hope that
this article shows that this is a very relevant context of use for robots: when
facing a child with school difficulties, robots can play the role of a naïve
learner which neither adults nor peers can convincingly play.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments}

We warmly thank all the children, teachers and staff of the International School
of Geneva, the Institut Florimont and the Haut-Lac school for their
participation and support. We express our gratitude to Anne Gossin and Fanny
Lebel for inviting us to their surgery, for their involvement in the experiments
and for bearing with our disruptive robots. And finally, we want to say a very
special \emph{Thank you!} to Vincent, Thomas, Valérie, Émilien, Mathieu, Johan,
Nicolas, Antoine, Adèle and Marie: by spending several hours being patient
teachers for our robots, you have paved the way for what may become tomorrow a
new way of learning how to deal with all these letters and words!

This research was partially supported by the Funda\c{c}\~{a}o para a Ci\^{e}ncia
e a Tecnologia (FCT) with reference UID/CEC/50021/2013, and by the Swiss
National Science Foundation through the National Centre of Competence in
Research Robotics.

\bibliographystyle{abbrv}
\bibliography{biblio}


\end{document}
