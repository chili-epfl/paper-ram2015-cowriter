%\documentclass[twocolumn]{article}
\documentclass{article}

\usepackage{graphicx} 
\usepackage{subfigure}
\usepackage{paralist}

\usepackage{hyperref}

\usepackage{url}
\usepackage{booktabs}

\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tikz}
\usetikzlibrary{positioning, calc}

\usepackage[draft,nomargin,footnote]{fixme}

\graphicspath{{figs/}}

\usepackage{xspace}
\newcommand{\eg}{\textit{e.g.}\xspace}
\newcommand{\etal}{\textit{et al.}\xspace}
\newcommand{\ie}{\textit{i.e.}\xspace}
\newcommand{\etc}{\textit{etc.}\xspace}
\newcommand{\vs}{\textit{vs.}\xspace}

\title{Learning by Teaching a Robot:\\The Case of Handwriting}

\author{S\'everin Lemaignan$^1$, Alexis Jacq$^{1,2}$, Fernando Garcia$^1$,
    Deanna Hood$^1$, \\Aude
    Billard$^1$, Ana Paiva$^2$, Pierre Dillenbourg$^1$ \\
$^1$CHILI Lab, \'Ecole Polytechnique F\'ed\'erale de Lausanne, Suisse,\\
$^2$Instituto Superior T\'{e}cnico, University of Lisbon, Portugal}

\begin{document}
\maketitle

%\begin{abstract}
%
%    Robots for education are not limited to support ICT teaching, and they are
%    indeed finding new roles in the classroom. This article reports on such a
%    new paradigm for educative robots, that involves \emph{learning by teaching}
%    and strong \emph{social engagement} to help children struggling with
%    handwriting. Our system relies on machine-learning and child-robot
%    interaction with a small humanoid robot, and we present several real-world
%    studies in schools and with occupational therapists that led us to promising
%    initial results.
%
%\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A Different Paradigm for Educative Robots}

Thomas is five and an half, and has been diagnosed with visuo-constructive
deficits. He is under the care of an occupational therapist, and tries to
workaround his inability to draw letters in a consistent manner. Vincent is six
and struggles at school with his poor handwriting and even poorer
self-confidence.\footnote{Children's names have been changed.}

While Thomas is lively and always quick at shifting his attention from one
activity to another, Vincent is shy and poised. Two very different children,
facing however the same difficulty to write in a legible manner. And, hidden
beyond this impaired skill, psycho-social difficulties also arise: they
underperform at school, Thomas has to go for follow-up visits every week,
they both live under the label ``requires special care''. This is a source of
anxiety for the children and for their parents alike.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{henry}
    \caption{\small Thomas teaching Nao how to write numbers, with the help of an
    occupational therapist.}
    \label{fig:henry}
\end{figure}

Remediations for handwriting difficulties traditionally involve long
interventions (at least 10 weeks, \cite{Hoy2011}), essentially consisting in
handwriting training with occupational therapists, and primarily addressing the
\emph{motor} deficits.  Improvements in self-confidence and anxiety occur (at
best) as a side-effect of the child improving his/her handwriting skills and,
consequently, improving his/her performance at school.

We present in this article a new take on this educative challenge, as a
remediation procedure that involve a ``bad writer'' robot that is \emph{taught}
by the child: by building on the \emph{learning by teaching} paradigm, not only
the child practises handwriting but, as (s)he takes on the role of the teacher,
(s)he also positively reinforce his/her self-esteem and motivation: his/her
social role shifts from the ``underperformer'' to ``the one who knows and
teaches''.

\subsection{Learning by Teaching}

The \emph{learning by teaching} paradigm, which engages the student in the act
of teaching another, has been shown to produce motivational, meta-cognitive, and
educational benefits in a range of disciplines~\cite{Rohrbeck2003}.  The
application of this paradigm to handwriting intervention remains, however,
unexplored. One reason for this may be due to the requirement of an
appropriately unskilled peer for the child to tutor: this may indeed prove
difficult if the child is the lowest performer in the class.  In some cases, it
may be appropriate for a peer or teacher to simulate a na\"ive learner for the
child to teach. For handwriting however, where one's skill level is visually
evident, this acting is likely to be rapidly detected. This motivates the use of
an artificial teachable agent which can be configured for a variety of skill
levels, and for which children do not have preconceptions about its handwriting
ability.

Robots have been used as teachers or social partners to promote children's
learning in a range of contexts, most commonly related to language
skills~\cite{han2010robot}, and less often to physical skills (such as
calligraphy~\cite{Matsui2013}). Looking at the converse (humans \emph{teaching}
robots), Werfel notes in~\cite{Werfel2014} that most of the work focuses on the
robot's benefits (in terms of language~\cite{Saunders2010} or
physical~\cite{Mulling2013} skills, for example) rather than the learning
experienced by the human tutor themselves.  Our work concentrates on this latter
aspect: by demonstrating handwriting to a robot, we aim at improving the
\emph{child's} performance. Note that our work must be distinguished from
``learning from demonstration'' approaches to robots learning physical skills,
as the agent we present is only simulating fine motor skills for interaction
purposes.

A robotic learning agent which employs the learning by teaching paradigm has
previously been developed by Tanaka and Matsuzoe~\cite{Tanaka2012}. In their
system, children learn vocabulary by teaching the {\sc nao} robot to act out
verbs. The robot is tele-operated (Wizard-Of-Oz) and mimics the actions that the
children teach it, but with no long-term memory or learning algorithm in place.
Our project significantly extends this line of work in two ways. First, by
investigating the context of children's acquisition of a challenging physical
skill (handwriting), and second by proposing a robotic partner which is fully
autonomous in its learning.

\subsection{Agency and Commitment}

We also investigate here a particular role for a robot in the
education of handwriting: not only is the robot actively performing the activity
by drawing letters, but it does so in a way that engages the child in a very
specific social role. The child is the teacher in this relationship and the
robot is the learner: the child must engage in a (meta-) cognitive relationship
with the robot to try to understand why the robot fails and how to help it best.
Here, the robot is more than just an activity facilitator or orchestrator -- its
physical presence and embodiment induce agency and anthropomorphising, and
cognitively engage the child into the learning activity.

Besides the commitment of the child into the interaction build on the
``prot\'eg\'e effect'': the teacher feels responsible for his student, commits
to the student's success and possibly experiences student's failure as his own
failure to teach. Teachable computer-based agents have previously been used to
encourage this ``prot\'eg\'e effect'', wherein students invest more effort into
learning when it is for a teachable agent than for themselves~\cite{Chase2009}.
We rely on this cognitive mechanism to reinforce the child's commitment into the
robot-mediated handwriting activity.

For these two reasons, our approach is to be distinguished from previous works in
educational robotic. Most of these do not consider the agency induced by the
robot beyond its motivational aspect: playing with an interactive, partially autonomous
device naturally induces some form of anthropomorphizing, which leads to some
level of projected agency, and participate the overall excitement (at least, on
the short-term, before the novelty effect vanishes).

In our case, the role of agency is stronger: it induces meta-cognition (``I am
interacting with an agent, so I need to reflect on how to best teach him'')
which is beneficial for the learning process; it also induces a prot\'eg\'e
effect (``I want my robot-agent to succeed!'') which support the commitment of
child into the interaction, also for longer period of time (we report in this
article upon two case studies where children were indeed interacting with the
same robot for several hours, spanned over several weeks).


Building on these socio-cognitive mechanisms, our intent is therefore to design
a robotic system that would effectively support handwriting remediation in an
original way: by getting children to teach a robotic agent how to write, those
children would both practise without knowing it and recover self-confidence and
self-esteem by supporting a worst-than-themselves robotic ``student''.

The following sections of the paper go into details. We first provides a
brief overview of the robotic system and the interaction it induces. We then
give the details of machine-learning techniques that allow the robot to learn
from the children, followed by the implementation on a {\sc nao} robot.

We then present and report on the four school experiments and the two case
studies that we conducted over the last two years. While the focus of the school
experiments was mostly technical validation and data acquisition, the two case
studies that lasted each about 4 weeks, gave us initial insights on the
relevance and effectiveness of our approach.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation of the Interaction}

Figure~\ref{experimental_setup} illustrates our general experimental setup: a
face-to-face child-robot interaction with an (autonomous) Aldebran's {\sc nao}
robot.

A tactile tablet (with a custom application) is used for both the robot and the
child to write: during a typical round, the child requests the robot to write
something (a single letter, a number or a full word), and push the tablet
towards the robot, the robot writes on the tablet by gesturing the writing (but
without actually physically touching the tablet), the child then pull back the
tablet, corrects the robot's attempt by writing him/herself on top or next to
the robot's writing (see Figure~\ref{fig:diego}), and ``send'' his/her
demonstration to the robot by pressing a small button on the tablet. The robot
``learns'' from this demonstration and tries again.

Since the child is assumed to take on the role of the teacher, we had to ensure
(s)he would be able to manage by him/herself the turn-taking and the overall
progression of the activity (moving to the next letter or word). In our design,
the turn-taking relies on the robot prompting for feedback once it is done with
its writing (simple sentences like ``What do you think?''), and pressing on a
small robot icon on the tablet once the child has finished correcting. In our
experiments, both were easy to grasp for children.


\begin{figure}
    \centering
    \includegraphics[width=0.6\columnwidth]{experimental_setup}
    \caption{\small Our experimental setup: face-to-face interaction with a {\sc
        nao} robot.  The robot writes on the tactile tablet, the child then
        corrects the robot by directly overwriting its letters on the tablet
        with a stylus. An adult (either a therapist or an experimenter,
        depending on the studies), remains next to the child to guide the work
        (prompting, turn taking, etc.). For some studies, a second tablet and an
        additional camera (dashed) are employed.}

    \label{experimental_setup}
\end{figure}

Implementing such a system raises several challenges: first, the acquisition,
analyse and learning from hand-written demonstration, which lays at the core of the
our approach, necessitates the development of several algorithms for the robot to generate
initial bad writing and to respond in an adequate manner, showing visible (but
not too quick) writing improvements.

Then, the actual implementation on the robot requires the coordination of
several modules (from performing gestures and acquiring the user's input to
the high-level state machine), spread over several devices (the robot itself,
one laptop and up to four tactile tablets for certain studies we conducted). We
relied on ROS to ensure the synchronization and communication between these
modules.

We detail each of these in the following sections.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Generating and Learning Letters}

Since our application is about teaching a robot to write, generating (initially
bad) letters and learning from demonstrations is a core aspect of the project.

The main insight for both the generation and the learning of letters is to
reason about the shape of letters in their eigenspace, instead of the natural
cartesian space. The eigenspace of each letters is spanned by the first $n$
eigenvectors (in our experiments, $3 < n < 6$) of the covariance matrix
generated from a standard dataset of adult letters (the UJI Pen Characters 2
dataset~\cite{Llorens2008}).  This procedure, based on a Principle Component
Analysis (PCA), is explained in details in a previously published
article~\cite{hood2015when}.

By changing the eigenvalues associated to these eigenvectors and regenerating
letters with the reverse procedure, it becomes then easy to generate new
letters, with distortions that are actually plausible handwriting errors: they
are actually \emph{exaggerations} of variance of writing styles that naturally
occurs amongst adult writers.  Figure~\ref{fig:sampleLetters} shows examples of
deformed ``g'' generated with such a technique.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{cowriter-g}
    \caption{\small \label{fig:sampleLetters} \textbf{Generating bad letters}:
        effect of varying the first five eigenvalues (rows) of the shape model
        of ``g'' by different factors (columns). The percentage of the total
        variance in the dataset explained by each eigenvalue is shown      on
        the appropriate row. Examples noted A, B, C, D illustrate how the
        PCA-based approach allows to \emph{automatically} generate letters whose
        errors can be \emph{semantically} interpreted, \eg A has a too large bottom
        loop, B has a wide top loop, the bottom loop of C is not correctly
        closed, the top loop of D is not closed, etc.}

\end{figure}

The same technique can also be applied to \emph{classify} demonstrations,
\emph{assess} their quality and \emph{learn} from them. Figure~\ref{fig:h} shows
for example 9 allographs of ``h'' written by a 6 years old child, along with the
mean letter from the dataset (reference letter). By projecting each of the
demonstrations onto the eigenspace of ``h'' (Figure~\ref{fig:h}b), we observe
that:

\begin{itemize}
    \item the different allographs can by clustered (with a $k$-means or
        mean-shift algorithm) by their visual styles,
    \item we can compute an euclidian distance to the reference letter to assess
        the visual proximity of the demonstration with the expected letter, thus
        providing a quantitative metric of writing performance.
\end{itemize}

\begin{figure}[ht!]
    \centering
    \subfigure[Nine allographs of the cursive ``h'', next to the reference]{
        \includegraphics[width=0.4\columnwidth]{h}
    }
    \subfigure[Same samples, normalized and projected in the eigenspace spanned from the
        3 first eigenvectors: clusters arise, that actually match writing styles.]{
        \includegraphics[width=0.4\columnwidth]{eigenspace-uniformization}
    }

    \caption{\small Projecting demonstrated letters onto the eigenspace
    generated from the reference dataset effectively clusters the samples
    according to their topological similarity. Allographs that are similar to
    the reference are close to it in the eigenspace.}
    \label{fig:h}
\end{figure}

The algorithm for machine-learning becomes then a simple matter of converging at
a specific pace towards the child demonstration in the eigenspace.
Figure~\ref{learning_6_demos}, at the end of the article, illustrates the
process with the complete learning cycle of the number ``6''.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Robotic Implementation}

Our system is embodied in an Aldebaran's {\sc nao} (V4 or V5, depending on the
studies) humanoid robot. This choice is motivated by its approachable
design~\cite{Gouaillier2008}, its size (58cm) and inherently safe structure
(lightweight plastic) making it suitable for close interaction with children,
its low price (making it closer to what school may afford in the coming years)
and finally its ease of deployment on the field.

Robotic handwriting requires precise closed-loop control of the arm and hand
motion. Because of the limited fine motor skills possible with such an
affordable robot, in addition to the absence of force feedback, we have opted
for \emph{simulated handwriting}: the robot draws letters in the air, and the
actual writing is displayed on a synchronised tablet.

\begin{figure}[ht!]
\centering

\resizebox{0.7\linewidth}{!}{%

\begin{tikzpicture}[
    >=latex,
    node distance=2cm,
    every edge/.style={draw, very thick},
    redarrow/.style={draw,red, text=black},
    greenarrow/.style={draw,GreenYellow,text=black},
    yellowarrow/.style={draw,BurntOrange,text=black},
    cmpt/.style={draw, align=center, rounded corners, inner sep=5pt, font=\sf, fill=black!20},
    label/.style={midway, align=left, font=\scriptsize\sf, fill=white, above,opacity=0,text opacity=1}]

    \node at (0,0) (laptop) {\includegraphics[width=2cm]{laptop}};
    \node[below right=2 of laptop] (nao) {\includegraphics[width=2cm]{nao}};
    \node[below left=2 of laptop] (tablet) {\includegraphics[width=2cm]{tablet+stylus}};
    \node[above=2 of laptop] (selection) {\includegraphics[width=2cm]{selection_tablet}};

    \node[draw,above right=2 of laptop,anchor=north west,text width=4cm] (processes)
    {\sf\scriptsize machine-learning, \\letters/gestures
    generation, \\interaction supervision};
    \path (laptop) edge[dashed] (processes);

    \path (nao) edge [->,redarrow, bend left] node[label, auto] {robot state} (laptop);
    \path (laptop) edge [->,greenarrow, bend left] node[label, auto] {writing gestures} (nao);

    \path (tablet) edge [->,redarrow, bend left] node[label, auto] {demonstrations,\\turn taking} (laptop);
    \path (laptop) edge [->,redarrow, bend left] node[label,
    auto=right,align=right]
    {path of\\ letters to display} (tablet);

    \path (selection) edge [->,redarrow] node[label, auto=right] {letter/word to write} (laptop);

    \path (-5, 2) edge [->, redarrow] node[label] {ROS} ++(1, 0);
    \path (-5, 2.6) edge [->, greenarrow] node[label] {NaoQI} ++(1, 0);
    
\end{tikzpicture}
}

\caption{\small \textbf{Overview of the system}. In total, the system runs about 10 ROS nodes,
    distributed over the robot itself, a central laptop and Android tablets.}

    \label{fig:archi}
\end{figure}

The overall architecture of the system (Figure~\ref{fig:archi}) is therefore
spread over several devices: the {\sc nao} robot itself, that we address via
both a ROS API\footnote{The ROS stack for {\sc nao} is available at
\url{http://wiki.ros.org/nao_robot}.} and the Aldebaran-provided NaoQI API, one
to four Android tablets (the main tablet is used to print the robot's letter and
to acquire the children's demonstrations; more tablets have been used in some
studies, either to let the child input words to be written, or for the
experimenter to qualitatively annotate the interaction in a synchronized
fashion), and a central laptop running the machine learning algorithms, the
robot's handwriting gesture generation and high level control of the activity.

Since the system does not actually require any CPU-intensive process, the laptop
can be removed and the whole logic run on the robot. Due to the relative
difficulty to deploy and debug ROS nodes directly on the robot, the laptop
remains however convenient during the development phase and we kept if during
our experiments.

Most of the nodes are written in Python, and the whole source code of the
project is available online\footnote{The primary repository is
\url{https://github.com/chili-epfl/cowriter_letter_learning}.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Field Studies}

To date, the system has been deployed and tested in three different
schools (totalling child-robot interactions with more than 70 children, aged 5
to 8) and we also conducted 2 case studies that lasted several weeks.
Table~\ref{studies} gives an overview of these studies.

\begin{table}[ht!]
\centering
\caption{\small Field studies conducted within the project}
\label{studies}
\footnotesize
\begin{tabular}{@{}lp{4cm}p{2.2cm}p{2cm}l@{}}
\toprule
{\bf Study}     & {\bf Type}                                    & {\bf Avg. duration}              & {\bf Children \#}                     & {\bf Ages} \\ \midrule
{\it ISG 1}     & Unstructured group interaction at school      & 16 min/group               & 4 $\times$ 8 children                 & 6-7        \\
{\it Florimont} & Individual/Pair interaction at school         & 11 min/group               & 7 (individual) + 7 $\times$ 2 (pairs) & 7-8        \\
{\it Vincent}     & Case-study, spanning over 4 weeks              & 1.5h $\times$ 4 weeks & 1                                     & 6          \\
{\it Haut-Lac}  & Pair interaction at school & 26 min/group                            & 7 $\times$ 2                          & 5-6        \\
{\it ISG 2}     & Individual interaction at school              & 18 min                            & 6                                     & 5-6        \\
{\it Thomas}     & Case-study, spanning over 4 weeks              & 1h $\times$ 4 weeks        & 1                                     & 5          \\ \bottomrule
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Studies at School}

Over the two years of the project, we conducted four studies in schools
(Figure~\ref{fig:schools}). These experiments were meant to technically validate
the system (is it actually able to autonomously write and learn from
demonstrations?) and test the interaction (is the apparatus easy to grasp and to
interact with for children?). We also studied the initial acceptance of the
robot in the school environment (through several formal and informal discussions
with teachers) and how children engage with the robot (and maintain or not this
engagement).

\begin{figure}
    \centering
    \includegraphics[height=3.9cm]{schools}
    \includegraphics[height=3.9cm]{schools2}
    \caption{\small The first field studies were focused on technical validation, with
    above 70 pupils interacting with the robot over short periods (around 15
minutes), either alone or in small groups.}
    \label{fig:schools}
\end{figure}

Critically, these studies were conducted with \emph{whole classes}: we decided
not to select specifically underperforming children as having more children (73
in total) was beneficial for these preliminary studies, and this would have
besides required careful organization with the school due to ethical concerns.

\paragraph{System validation}

From a technical perspective, the system achieves an acceptable level of
reliability and allow a technically sound autonomous interaction. For instance,
during the second school study (\textit{Florimont}), the robot withstood
interactions which lasted for a total of 160 minutes.  During this time the
robot wrote 335 letters, 152 of which in response to demonstrations received
from the 21 children. Technical intervention was only required for the three
instances that the robot fell during that day.  Otherwise, the technical
components of the system operated autonomously and as expected over the
sessions.

Due to the modular software architecture (about 10 ROS nodes), the occasional
crashes occurring during others sessions were usually quickly resolved by
re-launching the faulty node alone, and did not significantly impact the
interaction.

The otherwise technical limitations were related to some letters or writing
style (most notably, the ones requiring multiple strokes per letter) not being
adequately processed by the learning algorithm. Support for such letters has
been added as a follow-up of the studies.

\paragraph{Acceptance}

Children's recognition that the robot is writing by itself is critical for our
approach to be effective. When asked, no child indicated that they did not
believe that the robot was writing by itself. There were, at times, questions
about the robot's writing method at the beginning of the interaction, but when
advised that the robot ``tells the tablet what it wants to write,'' this was
accepted by the children.  Besides, teachers interviewed for their feedback on
the system advised that children are asked to draw letters in the air in a
similar manner as part of their handwriting education. The behaviour is hence
not unfamiliar to children.

More generally, the approach was well accepted and recognized as useful and
promising by teachers and parents; this was \textit{a posteriori} confirmed by
the numerous spontaneous contacts made by parents and therapists who were
looking forward to use the system with their children.

\paragraph{Sustained engagement}

As indicated in the introduction, the literature suggests that 20 handwriting
practice sessions is found to be the minimum to demonstrate effective results in
handwriting remediation~\cite{Hoy2011}. This highlights the necessity to sustain
a child-robot engagement over the long-term if we want to achieve measurable learning gains.

Factually, the children engaged into the teaching activity: in the
\textit{Florimont} study, for instance, they demonstrated an average of
10.9 demonstration letters (SD = 4.4) for an average session duration of 11 minutes.
In 9 out of the 14 sessions (64\%), the robot
received demonstration letters even \emph{after} reaching the final stage of the
interaction, suggesting an intrinsic motivation to further engage in the
interaction.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.9\linewidth]{engagement}
    \caption{\small Engagement level of one child, manually annotated by two judges
        over a 13 min long interaction (Cronbachâ€™s alpha test: $\alpha = .82$,
        good inter-judge agreement). 0 means ``complete disengagement from the
        task'', 6 means ``full engagement''. The vertical lines represent activity
    switches between handwriting teaching and story-telling (used as a
    distruber).}
    \label{engagement_level}
\end{figure}

We also conducted a qualitative assessment of the engagement levels during
several interaction sessions (studies \textit{Haut-Lac} and \textit{ISG 2}).
While the overall engagement was high, Figure~\ref{engagement_level} shows an
example of a child with moderate level of engagement. On-going research in our
group aims at assessing such engagement levels in real-time, so that the robot
can address possible disengagement (by changing/adapting its physical behaviour,
by switching to different activities, etc.)

We also performed further qualitative assessment of engagement over longer
interaction periods: two 4-weeks long case studies with one child at a time have
been conducted so far, the first one (\emph{Vincent}) focusing on
\emph{engagement on the long run}, the second one (\emph{Thomas}) looking at
\emph{acceptance and impact in a real therapeutic context}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Case Study 1: Vincent}

\paragraph{Context, Study Design}

During this first case study, we invited and followed Vincent, a six years old
child, once per week over a period of a month. Our primary aim was to address the
question of whether we can sustain Vincent's engagement and commitment to the
writing activity over such a period.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{diego}
    \caption{\small Vincent correcting {\sc nao}'s attempt by rewriting the
        whole word. Empty boxes are drawn on the screen to serve as template for the child
        and to make word segmentation more robust.}
    \label{fig:diego}
\end{figure}

The study took place at our laboratory (Figure~\ref{fig:diego}), and we chose to
design the activity around a storyline meant to be attractive for a 6 years old
boy: one of our {\sc nao} was away for a mysterious scientific mission, and it
needed the support of another one -- which stayed at the lab -- to interpret
curious pictures that were sent every week. Vincent had to help the second robot
understanding the pictures, and since the two robots had somehow beforehand
agreed to communicate with ``letters written like humans'' (\ie handwritten),
Vincent also had to help the robot to write good looking letters (because, well,
this robot was terrible at writing!) The experimental setup was similar to
Figure~\ref{experimental_setup}, except that Vincent had to tell the robot what
to write with small plastic letters (visible behind the robot on Figure~\ref{fig:diego}).

To complement the intrinsic motivation of helping a robot to communicate with another one, we
gradually increased the complexity of Vincent's task to keep it challenging and
interesting (the first week: demonstration of single letters; the second week:
short words; the third week: a full letter -- Figure~\ref{fig:stimuli}).

The last session was set as a test: the ``explorer'' robot
had come back from its mission and it actually challenged the other robot in
front of Vincent: \emph{``I don't believe you wrote yourself these nice letters that I
received! Prove it to me by writing something in front of me!''} This situation
was meant to evidence the Prot\'eg\'e effect: by judging the other robot's
handwriting, the ``explorer'' robot would implicitly judge Vincent's skills as
teacher, and in turn, Vincent's handwriting.

\paragraph{Results}

\begin{figure}
    \centering
    \subfigure[Initial letter, generated by the robot]{
        \includegraphics[height=6cm]{diego-initial-letter}
    }
    \subfigure[Final letter, after training with Vincent]{
        \includegraphics[height=6cm]{diego-final-letter}
    }

    \caption{\small (French) text generated by the robot, before and after a one
        hour long interaction session with the child. As an example, the red box
        highlights the changes on the word ``envoyer''.}

    \label{fig:stimuli}
\end{figure}

Overall, Vincent provided 154 demonstrations to the robot, and he remained
actively engaged over the four weeks. The story was well accepted by Vincent and
he seriously engaged into the game. After the first week, he showed good
confidence to play with the robot and he built affective bonds with the robot
over the course of the study, as evidenced by some cries on the last session,
and a letter sent by him to the robot 4 months \emph{after} the end of the study
to get news. This represents a promising initial result: we can effectively keep
a child engaged with the robot for a relatively long period of time (about 5
hours).

No conclusion can be drawn in terms of actual handwriting remediation: we did
not design this study to formally assess possible improvements.  However, as
pictured on Figure~\ref{fig:stimuli}, Vincent was able to significantly improve
the robot's skill, and he acknowledged that he had been able to help the robot:
in that regard, Vincent convinced himself that he was ``good enough'' at writing
to help someone else, and this is likely to have positively impacted his
self-esteem.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Case Study 2: Thomas}

\paragraph{Context, Study Design}

The second long-term study was designed with the help of an occupational therapist in
Geneva and aimed at deploying the system for the first time on a real
therapeutic case.

Thomas is a 5.5 years old child, under the care of an occupational therapist. He
has been diagnosed with visuo-constructive deficits, which translate into
difficulties for him to consistently draw letters. Besides, focusing on a task
is difficult for Thomas, who tends to rapidly shift his attention to something
else. Since the robot's learning algorithm requires repeated demonstrations of
similarly shaped letters to converge, the occupational therapist was especially
interested in observing if the robot would induce a strong enough motivation for
Thomas to focus on producing regular, consistent letters, thus overcoming his
deficit.

The experiment took place at the therapist's surgery (four sessions spanning
over 5 weeks). Contrary to Vincent's experiment, we chose not to introduce any
storyline beyond a simple prompt (``the robot wants to participate to a robotic
handwriting contest, will you help him to prepare?''), only provided during the
first session. Hence, we also tested during this case-study if the robot (and
the Prot\'eg\'e effect) would induce a strong enough intrinsic motivation to
keep the child engage over the five weeks.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{learning_6_demos}
    \caption{\small Thomas' demonstrations for the number ``6'' (top row) and
        the corresponding shapes generated by the robot (bottom row). After
        eight demonstrations, Thomas decided that the robot's ``6'' was good enough,
        and went to another character. In that regard, he was the one
        responsible for the learning process of the robot.}

    \label{learning_6_demos}
\end{figure}


The occupational therapist had recently carried activities with Thomas about
writing numbers, so we decided with her to focus on these as well: Thomas would
use a secondary tablet to tell the robot what number to write, and would then
correct the robot's attempts like in the other experiments.
Figure~\ref{learning_6_demos} shows the attempts/corrections cycles that
occurred during one of the session, on the number ``6''.

%Before the experiment, Thomas was working on writing numbers with the therapist.
%Hence we decided to turn the CoWriter activity to teach numbers to the robot.
%Build on existing iPad applications actually used by occupational therapists
%(Dawson Toth's \emph{ABC's Writer}), we designed an Android application for
%pre-test and post-test. It consisted in drawing numbers following an helping
%pattern, that becomes more fine with levels in order to increase
%difficulty~\ref{fig:abc-writer}.

Since Thomas would frequently draw mirrored numbers, or hard-to-recognize
shapes, the learning algorithm of the robot tended to converge towards
meaningless scribblings. We addressed this issue by having the robot to
\emph{refuse} allographs that were too far from the reference shape (\emph{``I'm
not sure to understand what you are drawing...''}), so that the child had to
pay good attention to what he would demonstrate to the robot. Also, to make
the robot's progresses evident, we modified the initialization step of the
learning algorithm to start with a roughly vertical stroke instead of a
deformed number (round 0 on Figure~\ref{learning_6_demos}).

%\begin{figure}
%    \centering
%    \includegraphics[width=0.9\linewidth]{abc-writer}
%    \caption{\small Screenshot of the Android application developed to be used as
%    pre-test and post-test: the child must follow with his finger the path of
%the letter or number. We count the number of times the finger goes outside of
%the red-bordered area.}
%    \label{fig:abc-writer}
%\end{figure}
%

\paragraph{Results}

Despite his attention deficit, Thomas was able to conduct the activity during
more than forty minutes in each session. In total, 55 allographs out of the 82
shapes demonstrated by the child were accepted by the robot (with a progressive
improvement from 13 out of 28 in the first session up to 26 out of 29 in the
last session).

As soon as Thomas understood that the robot was only accepting well-formed
allographs, he started to focus on it and he would typically draw 5 or 6 times
the number before actually sending to the robot (the tablet let the children
clear their drawing and try again before sending it to the robot). According to
the therapist, it was the first time that Thomas would correct himself in such a
way, explicitly having to reflect on how \emph{another agent} (the robot) would
interpret and understand his writing.

Since the robot's handwriting started from a simple primitive (a stroke), each
time Thomas succeeded to have his demonstration accepted by it, the robot's
improvement was clearly visible (as measured in Figure~\ref{henry_distances}).
This led to a self-rewarding situation that effectively supported Thomas'
engagement.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{learning_6_distances}
    \caption{\small \textbf{Assessing handwriting progress}: Euclidian
    distance in the eigenspace of the number ``6''. Green lines represent the robot performance,
    blue lines Thomas's performance. The round IDs ($x$-axis) correspond to the demonstrations
pictured on Figure~\ref{learning_6_demos}.}
    \label{henry_distances}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

We believe that this research provides a novel perspective on educative
robots at several levels. We show that:

\begin{itemize}
    \item robots in an educative context are \textbf{relevant and effective beyond ICT
        teaching},

    \item we can successfully \textbf{transpose the well-established
        \emph{learning by teaching} paradigm} from education sciences to
        robotics, even in a \textbf{complex form}: handwriting is difficult
        physical skill, the robot learns and interact autonomously, the child is
        responsible not only for the teaching but also for the teaching
        orchestration by managing the turn taking and the progression of the
        activity,

    \item blending machine-learning techniques with human-robot interaction
        allows for building a \textbf{believable agent}, that induces
        \textbf{social commitment},

    \item this proves essential to \textbf{sustain a long-term interaction} (several
        hours) around a fundamentally routine -- yet challenging -- educational
        task (handwriting learning),

    \item besides, the social commitment induces a \textbf{cognitive engagement}
        of the child with the robot which is \textbf{a key learning lever} as
        its elicits \textbf{reflective, meta-cognitive mechanisms on the
        learning task}.
\end{itemize}


The place and role of the robot \textit{vis-\`a-vis} the teacher can be
questioned: as we see it, the role of the robot within the classroom (or at the
therapist's surgery) does not infringe upon the role of the adult (teacher or
therapist).  The core of the \emph{learning by teaching} paradigm relies on the
child becoming the teacher of an underperforming pupil (the robot): from that
perspective, the robot does not replace the teacher, on the contrary. It plays a
different role in the classroom, which happen to be novel as well: the robot is
the \emph{least} performing student, and still a very patient, always eager to
improve, one.

The importance of the adult is further supported by our experiments: even with
an autonomous, nominally performing robot, to put the teacher's clothes on
remains (expectedly) difficult for 5-6 years old children, and during the
experiments we conducted, the adult always played a key role at prompting the
child to give feedback to the robot or to move to the next letter or word.  At a
higher orchestration level (and as reported in the two case studies with Vincent
and Thomas), the educational scenarios were also always designed and monitored
by the adults.

We initially envisioned our system to be run in the back of a classroom with one
child: this would have allowed an individual, face-to-face remediation approach,
not otherwise tractable for a teacher with 20 pupils.  This is however unlikely
to happen soon. In our experience, the teacher keeps such an important role that
the interaction (and the learning!) would hardly occur if the child is left
alone (or even semi-alone). We can therefore reassure teachers: robots are not
going to replace them any time soon.

Beyond handwriting, we however do believe that this work provides a novel
perspective on the role for robots in the field of education. \emph{Learning by
teaching} is a powerful paradigm because of not only its pedagogical efficacy,
but its potential to positively impact the child's motivation and self-esteem.
We hope that this article shows that this is a very relevant context of use for
robots: when facing a child with school difficulties, robots can play the role
of a na\"ive learner which neither adults nor peers -- because of the social
effects it would induce -- can convincingly play.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments}

This research was partially supported by the Funda\c{c}\~{a}o para a Ci\^{e}ncia
e a Tecnologia (FCT) with reference UID/CEC/50021/2013, and by the Swiss
National Science Foundation through the National Centre of Competence in
Research Robotics.

\bibliographystyle{abbrv}
\bibliography{biblio}


\end{document}
